{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR1o7wbGQMAL"
      },
      "source": [
        "###constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YeuPGlhROqYf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "gaussian_kernel = (\n",
        "    np.array(\n",
        "        [\n",
        "            [1,  4,  6,  4, 1],\n",
        "            [4, 16, 24, 16, 4],\n",
        "            [6, 24, 36, 24, 6],\n",
        "            [4, 16, 24, 16, 4],\n",
        "            [1,  4,  6,  4, 1]\n",
        "        ]\n",
        "    )\n",
        "    / 256\n",
        ")\n",
        "\n",
        "\n",
        "yiq_from_rgb = (\n",
        "    np.array(\n",
        "            [\n",
        "                [0.29900000,  0.58700000,  0.11400000],\n",
        "                [0.59590059, -0.27455667, -0.32134392],\n",
        "                [0.21153661, -0.52273617,  0.31119955]\n",
        "            ]\n",
        "        )\n",
        "    ).astype(np.float32)\n",
        "\n",
        "\n",
        "rgb_from_yiq = np.linalg.inv(yiq_from_rgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZI_43gaQoUz"
      },
      "source": [
        "### processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FgOJOhEAQjdc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "# from constants import rgb_from_yiq, yiq_from_rgb\n",
        "\n",
        "\n",
        "def loadVideo(video_path):\n",
        "    image_sequence = []\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    while video.isOpened():\n",
        "        ret, frame = video.read()\n",
        "\n",
        "        if ret is False:\n",
        "            break\n",
        "\n",
        "        image_sequence.append(frame[:, :, ::-1])\n",
        "\n",
        "    video.release()\n",
        "\n",
        "    return np.asarray(image_sequence), fps\n",
        "\n",
        "\n",
        "def rgb2yiq(rgb_image):\n",
        "    image = rgb_image.astype(np.float32)\n",
        "    return image @ yiq_from_rgb.T\n",
        "\n",
        "\n",
        "def yiq2rgb(yiq_image):\n",
        "    image = yiq_image.astype(np.float32)\n",
        "    return image @ rgb_from_yiq.T\n",
        "\n",
        "\n",
        "def pyrDown(image, kernel):\n",
        "    return cv2.filter2D(image, -1, kernel)[::2, ::2]\n",
        "\n",
        "\n",
        "def pyrUp(image, kernel, dst_shape=None):\n",
        "    dst_height = image.shape[0] + 1\n",
        "    dst_width = image.shape[1] + 1\n",
        "\n",
        "    if dst_shape is not None:\n",
        "        dst_height -= (dst_shape[0] % image.shape[0] != 0)\n",
        "        dst_width -= (dst_shape[1] % image.shape[1] != 0)\n",
        "\n",
        "    height_indexes = np.arange(1, dst_height)\n",
        "    width_indexes = np.arange(1, dst_width)\n",
        "\n",
        "    upsampled_image = np.insert(image, height_indexes, 0, axis=0)\n",
        "    upsampled_image = np.insert(upsampled_image, width_indexes, 0, axis=1)\n",
        "\n",
        "    return cv2.filter2D(upsampled_image, -1, 4 * kernel)\n",
        "\n",
        "\n",
        "def idealTemporalBandpassFilter(images,\n",
        "                                fps,\n",
        "                                freq_range,\n",
        "                                axis=0):\n",
        "\n",
        "    fft = np.fft.fft(images, axis=axis)\n",
        "    frequencies = np.fft.fftfreq(images.shape[0], d=1.0/fps)\n",
        "\n",
        "    low = (np.abs(frequencies - freq_range[0])).argmin()\n",
        "    high = (np.abs(frequencies - freq_range[1])).argmin()\n",
        "\n",
        "    fft[:low] = 0\n",
        "    fft[high:] = 0\n",
        "\n",
        "    return np.fft.ifft(fft, axis=0).real\n",
        "\n",
        "\n",
        "def reconstructGaussianImage(image, pyramid):\n",
        "    reconstructed_image = rgb2yiq(image) + pyramid\n",
        "    reconstructed_image = yiq2rgb(reconstructed_image)\n",
        "    reconstructed_image = np.clip(reconstructed_image, 0, 255)\n",
        "\n",
        "    return reconstructed_image.astype(np.uint8)\n",
        "\n",
        "\n",
        "def reconstructLaplacianImage(image, pyramid, kernel):\n",
        "    reconstructed_image = rgb2yiq(image)\n",
        "\n",
        "    for level in range(1, pyramid.shape[0] - 1):\n",
        "        tmp = pyramid[level]\n",
        "        for curr_level in range(level):\n",
        "            tmp = pyrUp(tmp, kernel, pyramid[level - curr_level - 1].shape[:2])\n",
        "        reconstructed_image += tmp.astype(np.float32)\n",
        "\n",
        "    reconstructed_image = yiq2rgb(reconstructed_image)\n",
        "    reconstructed_image = np.clip(reconstructed_image, 0, 255)\n",
        "\n",
        "    return reconstructed_image.astype(np.uint8)\n",
        "\n",
        "\n",
        "def getGaussianOutputVideo(original_images, filtered_images):\n",
        "    video = np.zeros_like(original_images)\n",
        "\n",
        "    for i in tqdm.tqdm(range(filtered_images.shape[0]),\n",
        "                       ascii=True,\n",
        "                       desc=\"Video Reconstruction\"):\n",
        "\n",
        "        video[i] = reconstructGaussianImage(\n",
        "                    image=original_images[i],\n",
        "                    pyramid=filtered_images[i]\n",
        "                )\n",
        "\n",
        "    return video\n",
        "\n",
        "\n",
        "def getLaplacianOutputVideo(original_images, filtered_images, kernel):\n",
        "    video = np.zeros_like(original_images)\n",
        "\n",
        "    for i in tqdm.tqdm(range(original_images.shape[0]),\n",
        "                       ascii=True,\n",
        "                       desc=\"Video Reconstruction\"):\n",
        "\n",
        "        video[i] = reconstructLaplacianImage(\n",
        "                    image=original_images[i],\n",
        "                    pyramid=filtered_images[i],\n",
        "                    kernel=kernel\n",
        "                )\n",
        "\n",
        "    return video\n",
        "\n",
        "\n",
        "def saveVideo(video, saving_path, fps):\n",
        "    (height, width) = video[0].shape[:2]\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "    writer = cv2.VideoWriter(saving_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for i in tqdm.tqdm(range(len(video)), ascii=True, desc=\"Saving Video\"):\n",
        "        writer.write(video[i][:, :, ::-1])\n",
        "\n",
        "    writer.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmfJwai2QVHx"
      },
      "source": [
        "### gaussian pyramid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fhTXLw3BQYro"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "# from processing import idealTemporalBandpassFilter, pyrDown, pyrUp, rgb2yiq\n",
        "\n",
        "\n",
        "def generateGaussianPyramid(image, kernel, level):\n",
        "    image_shape = [image.shape[:2]]\n",
        "    downsampled_image = image.copy()\n",
        "\n",
        "    for _ in range(level):\n",
        "        downsampled_image = pyrDown(image=downsampled_image, kernel=kernel)\n",
        "        image_shape.append(downsampled_image.shape[:2])\n",
        "\n",
        "    gaussian_pyramid = downsampled_image\n",
        "    for curr_level in range(level):\n",
        "        gaussian_pyramid = pyrUp(\n",
        "                            image=gaussian_pyramid,\n",
        "                            kernel=kernel,\n",
        "                            dst_shape=image_shape[level - curr_level - 1]\n",
        "                        )\n",
        "\n",
        "    return gaussian_pyramid\n",
        "\n",
        "\n",
        "def getGaussianPyramids(images, kernel, level):\n",
        "    gaussian_pyramids = np.zeros_like(images, dtype=np.float32)\n",
        "\n",
        "    for i in tqdm.tqdm(range(images.shape[0]),\n",
        "                       ascii=True,\n",
        "                       desc='Gaussian Pyramids Generation'):\n",
        "\n",
        "        gaussian_pyramids[i] = generateGaussianPyramid(\n",
        "                                    image=rgb2yiq(images[i]),\n",
        "                                    kernel=kernel,\n",
        "                                    level=level\n",
        "                        )\n",
        "\n",
        "    return gaussian_pyramids\n",
        "\n",
        "\n",
        "def filterGaussianPyramids(pyramids,\n",
        "                           fps,\n",
        "                           freq_range,\n",
        "                           alpha,\n",
        "                           attenuation):\n",
        "\n",
        "    filtered_pyramids = idealTemporalBandpassFilter(\n",
        "                            images=pyramids,\n",
        "                            fps=fps,\n",
        "                            freq_range=freq_range\n",
        "                        ).astype(np.float32)\n",
        "\n",
        "    filtered_pyramids *= alpha\n",
        "    filtered_pyramids[:, :, :, 1:] *= attenuation\n",
        "\n",
        "    return filtered_pyramids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdFTbLO1QbkU"
      },
      "source": [
        "### laplacian pyramid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4eEiNII6Qez1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "from scipy.signal import butter\n",
        "\n",
        "# from processing import pyrDown, pyrUp, rgb2yiq\n",
        "\n",
        "\n",
        "def generateLaplacianPyramid(image, kernel, level):\n",
        "    laplacian_pyramid = []\n",
        "    prev_image = image.copy()\n",
        "\n",
        "    for _ in range(level):\n",
        "        downsampled_image = pyrDown(image=prev_image, kernel=kernel)\n",
        "        upsampled_image = pyrUp(image=downsampled_image,\n",
        "                                kernel=kernel,\n",
        "                                dst_shape=prev_image.shape[:2])\n",
        "        laplacian_pyramid.append(prev_image - upsampled_image)\n",
        "        prev_image = downsampled_image\n",
        "\n",
        "    return laplacian_pyramid\n",
        "\n",
        "\n",
        "def getLaplacianPyramids(images, kernel, level):\n",
        "    laplacian_pyramids = []\n",
        "\n",
        "    for image in tqdm.tqdm(images,\n",
        "                           ascii=True,\n",
        "                           desc=\"Laplacian Pyramids Generation\"):\n",
        "\n",
        "        laplacian_pyramid = generateLaplacianPyramid(\n",
        "                                    image=rgb2yiq(image),\n",
        "                                    kernel=kernel,\n",
        "                                    level=level\n",
        "                        )\n",
        "        laplacian_pyramids.append(laplacian_pyramid)\n",
        "\n",
        "    return np.asarray(laplacian_pyramids, dtype='object')\n",
        "\n",
        "\n",
        "def filterLaplacianPyramids(pyramids,\n",
        "                            level,\n",
        "                            fps,\n",
        "                            freq_range,\n",
        "                            alpha,\n",
        "                            lambda_cutoff,\n",
        "                            attenuation):\n",
        "\n",
        "    filtered_pyramids = np.zeros_like(pyramids)\n",
        "    delta = lambda_cutoff / (8 * (1 + alpha))\n",
        "    b_low, a_low = butter(1, freq_range[0], btype='low', output='ba', fs=fps)\n",
        "    b_high, a_high = butter(1, freq_range[1], btype='low', output='ba', fs=fps)\n",
        "\n",
        "    lowpass = pyramids[0]\n",
        "    highpass = pyramids[0]\n",
        "    filtered_pyramids[0] = pyramids[0]\n",
        "\n",
        "    for i in tqdm.tqdm(range(1, pyramids.shape[0]),\n",
        "                       ascii=True,\n",
        "                       desc=\"Laplacian Pyramids Filtering\"):\n",
        "\n",
        "        lowpass = (-a_low[1] * lowpass\n",
        "                   + b_low[0] * pyramids[i]\n",
        "                   + b_low[1] * pyramids[i - 1]) / a_low[0]\n",
        "        highpass = (-a_high[1] * highpass\n",
        "                    + b_high[0] * pyramids[i]\n",
        "                    + b_high[1] * pyramids[i - 1]) / a_high[0]\n",
        "\n",
        "        filtered_pyramids[i] = highpass - lowpass\n",
        "\n",
        "        for lvl in range(1, level - 1):\n",
        "            (height, width, _) = filtered_pyramids[i, lvl].shape\n",
        "            lambd = ((height ** 2) + (width ** 2)) ** 0.5\n",
        "            new_alpha = (lambd / (8 * delta)) - 1\n",
        "\n",
        "            filtered_pyramids[i, lvl] *= min(alpha, new_alpha)\n",
        "            filtered_pyramids[i, lvl][:, :, 1:] *= attenuation\n",
        "\n",
        "    return filtered_pyramids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SDzyVGjQP8Z"
      },
      "source": [
        "### evm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "E6F73ODtQSZF",
        "outputId": "da1f72f1-584b-4e8a-a61a-56050273c82b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Laplacian Pyramids Generation: 100%|##########| 405/405 [00:11<00:00, 35.10it/s]\n",
            "Laplacian Pyramids Filtering: 100%|##########| 404/404 [00:09<00:00, 44.11it/s]\n",
            "Video Reconstruction: 100%|##########| 405/405 [00:25<00:00, 15.78it/s]\n",
            "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
            "Saving Video: 100%|##########| 405/405 [00:05<00:00, 68.83it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def gaussian_evm(video_path, saving_path, level=4, alpha=100, low_omega=0.833, high_omega=1, attenuation=1):\n",
        "    images, fps = loadVideo(video_path)\n",
        "\n",
        "    gaussian_pyramids = getGaussianPyramids(images=images, kernel=gaussian_kernel, level=level)\n",
        "    filtered_pyramids = filterGaussianPyramids(pyramids=gaussian_pyramids, fps=fps, freq_range=[low_omega, high_omega], alpha=alpha, attenuation=attenuation)\n",
        "    output_video = getGaussianOutputVideo(original_images=images, filtered_images=filtered_pyramids)\n",
        "\n",
        "    saveVideo(video=output_video, saving_path=saving_path, fps=fps)\n",
        "\n",
        "def laplacian_evm(video_path, saving_path, level=4, alpha=100, lambda_cutoff=1000, low_omega=0.833, high_omega=1, attenuation=1):\n",
        "    images, fps = loadVideo(video_path)\n",
        "\n",
        "    laplacian_pyramids = getLaplacianPyramids(images=images, kernel=gaussian_kernel, level=level)\n",
        "    filtered_pyramids = filterLaplacianPyramids(pyramids=laplacian_pyramids, fps=fps, freq_range=[low_omega, high_omega], alpha=alpha, attenuation=attenuation, lambda_cutoff=lambda_cutoff, level=level)\n",
        "    output_video = getLaplacianOutputVideo(original_images=images, filtered_images=filtered_pyramids, kernel=gaussian_kernel)\n",
        "\n",
        "    saveVideo(video=output_video, saving_path=saving_path, fps=fps)\n",
        "\n",
        "# Define your Colab-specific input parameters\n",
        "video_path = \"/home/maharathy1/MTP/CV_Project/data/birds.mp4\"\n",
        "saving_path = \"/home/maharathy1/MTP/CV_Project/results/magnified_birds_optimal.mp4\"\n",
        "level = 6\n",
        "alpha = 30\n",
        "low_omega = 1\n",
        "high_omega = 5\n",
        "attenuation = 0.1\n",
        "lambda_cutoff = 16\n",
        "\n",
        "# Choose between Gaussian or Laplacian mode\n",
        "mode = 'laplacian'\n",
        "\n",
        "# Perform EVM based on the chosen mode\n",
        "if mode == 'gaussian':\n",
        "    gaussian_evm(video_path, level=level, alpha=alpha, low_omega=low_omega, high_omega=high_omega, saving_path=saving_path, attenuation=attenuation)\n",
        "else:\n",
        "    lambda_cutoff = 1000\n",
        "    laplacian_evm(video_path, level=level, alpha=alpha, lambda_cutoff=lambda_cutoff, low_omega=low_omega, high_omega=high_omega, saving_path=saving_path, attenuation=attenuation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##Motion Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OKCfwzN3lg96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
            "Saving Video: 100%|##########| 400/400 [00:03<00:00, 105.45it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "def load_video(video_path):\n",
        "    \"\"\"Loads a video from the given path and converts each frame to grayscale.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return []\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        frames.append(gray_frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "def motion_extraction(frames, shift=1):\n",
        "    \"\"\"Extracts motion between frames separated by a given shift.\"\"\"\n",
        "    if not frames:\n",
        "        print(\"No frames available for motion extraction.\")\n",
        "        return []\n",
        "    motion_frames = []\n",
        "    for i in range(len(frames) - shift):\n",
        "        diff = cv2.absdiff(frames[i + shift], frames[i])\n",
        "        motion_frames.append(diff)\n",
        "    return motion_frames\n",
        "\n",
        "def enhance_motion(frames, kernel_size=5, apply_glow=False):\n",
        "    \"\"\"Applies a Gaussian blur to enhance the motion frames.\"\"\"\n",
        "    if not frames:\n",
        "        print(\"No motion frames available for enhancement.\")\n",
        "        return []\n",
        "    enhanced_frames = []\n",
        "    for frame in frames:\n",
        "        if apply_glow:\n",
        "            glow = cv2.GaussianBlur(frame, (kernel_size, kernel_size), 0)\n",
        "            frame = cv2.addWeighted(frame, 0.5, glow, 0.5, 0)\n",
        "        else:\n",
        "            frame = cv2.GaussianBlur(frame, (kernel_size, kernel_size), 0)\n",
        "        enhanced_frames.append(frame)\n",
        "    return enhanced_frames\n",
        "\n",
        "def display_frames(frames,path):\n",
        "\n",
        "    height, width = frames[0].shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
        "    writer = cv2.VideoWriter(path, fourcc, 60.0, (width, height))\n",
        "\n",
        "    for i in tqdm.tqdm(range(len(frames)), ascii=True, desc=\"Saving Video\"):\n",
        "        # Convert grayscale frame to 3-channel (BGR) image\n",
        "        frame_bgr = cv2.cvtColor(frames[i], cv2.COLOR_GRAY2BGR)\n",
        "        writer.write(frame_bgr)\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "# Main execution block\n",
        "video_path = \"/home/maharathy1/MTP/CV_Project/results/magnified_birds_optimal.mp4\"\n",
        "saving_path = \"/home/maharathy1/MTP/CV_Project/me_results/birds_final.mp4\"\n",
        "frames = load_video(video_path)\n",
        "if frames:\n",
        "    motion_frames = motion_extraction(frames, shift=5)\n",
        "    enhanced_frames = enhance_motion(motion_frames, apply_glow=True)\n",
        "    display_frames(enhanced_frames,saving_path)\n",
        "else:\n",
        "    print(\"Failed to process video.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
